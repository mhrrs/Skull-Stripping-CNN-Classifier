{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01506d77",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "\n",
    "This model expects the files to be in a slightly different file structure detailed below:\n",
    "\n",
    " - Skull-Stripping-CNN-Repo\n",
    "\n",
    "    - torch_preProcessing2.ipynb\n",
    "    \n",
    "    - data\n",
    "        - files\n",
    "            - all of the .nii.gz files (do not unzip them)\n",
    "        - labels.csv\n",
    "        \n",
    "      \n",
    "The scripts in /processing_scripts were used to extract the new perfect scans into the proper file structure & generate the labels for them. \n",
    "\n",
    "Otherwise everything else should be pretty similar if not the same\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92bbe965-f99c-4b7f-b4dd-828d5eaadc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import Softmax\n",
    "from torch.nn.modules.activation import ReLU\n",
    "from torchsummary import summary\n",
    "\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712dda6-8ab9-4cc9-8352-82331723ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfilepath = './data/files/IXI369-Guys-0924-T1_bet_03.nii.gz'\n",
    "sfilepath = './data/files/IXI369-Guys-0924-T1_bet_8.nii.gz'\n",
    "\n",
    "\n",
    "def process_scan_file(filepath):\n",
    "    # Load the image data from the file\n",
    "    image = nib.load(filepath)\n",
    "\n",
    "    # Get the image data as a numpy array\n",
    "    data = image.get_fdata()\n",
    "\n",
    "    # Select the slice index you want to display or save (e.g., slice 20)\n",
    "    slice_index = 100\n",
    "    center = 90\n",
    "\n",
    "    # Display the image data for the selected slice\n",
    "    plt.imshow(data[:,center,:], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Save the image for the selected slice as JPEG\n",
    "    # plt.imsave(f'slice_{center}.jpg', data[:,center,:], cmap='gray')\n",
    "\n",
    "    \n",
    "print(\"non-stripped\")\n",
    "process_scan_file(nfilepath)\n",
    "\n",
    "print(\"stripped\")\n",
    "process_scan_file(sfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db475cd0-41f5-43e7-961e-cf4cc5174321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unzip_files(folderpath):\n",
    "    \n",
    "#     for file in os.listdir(folderpath):\n",
    "#         filepath = os.path.join(folderpath, file)\n",
    "    \n",
    "#         with gzip.open(filepath, 'rb') as f_in:\n",
    "#             outpath = os.path.splitext(filepath)[0]\n",
    "#             print(f\"outpath: {outpath} | filename: {file[:-3]}\")\n",
    "#             outputfolder = os.path.join(\"./image_data/BSE_BET_DATA/nifti_files\", file[:-3])\n",
    "#             with open(outputfolder, 'wb') as f_out:\n",
    "#                 f_out.write(f_in.read())\n",
    "#         print(file)\n",
    "    \n",
    "\n",
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def display_scan(data):\n",
    "    # Select the slice index you want to display or save (e.g., slice 20)\n",
    "    slice_index = 100\n",
    "    center = 32\n",
    "\n",
    "    # Display the image data for the selected slice\n",
    "    plt.imshow(data[:,:,center], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Save the image for the selected slice as JPEG\n",
    "    plt.imsave(f'slice_{center}.jpg', data[:,center,:], cmap='gray')\n",
    "\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # Read scan\n",
    "    volume = read_nifti_file(path)\n",
    "    # Normalize\n",
    "    volume = normalize(volume)\n",
    "    # Resize width, height and depth\n",
    "    volume = resize_volume(volume)\n",
    "    \n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84143329-4bae-4b23-a072-6a7f20f73bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#folderpath = \"./data/files\"\n",
    "nifti_folder = \"./data/files\"\n",
    "\n",
    "# uncomment this if you haven't unzipped the folders\n",
    "#unzip_files(folderpath)\n",
    "\n",
    "for file in os.listdir(nifti_folder):\n",
    "    path = os.path.join(nifti_folder, file)\n",
    "    img = process_scan(path)\n",
    "    print(img.shape)\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89583e1c-7f39-4cd3-90a7-07c43c4ba0db",
   "metadata": {},
   "source": [
    "# Break up the Nifti_files folder into three different folders: recognizable and perfect and other\n",
    "Recognizable will be known as non_strip, and other will be known as stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f5b78-af9d-431b-9f13-1b89a7f173c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nifti_folder = \"./data/files\"\n",
    "\n",
    "csv = np.loadtxt(\"./data/labels.csv\", delimiter=\",\", dtype=str)\n",
    "\n",
    "recognizable = []\n",
    "perfect = []\n",
    "data_loss = []\n",
    "\n",
    "for item in csv:\n",
    "    if item[1] == \"Yes\":\n",
    "        recognizable.append(item[0])\n",
    "    \n",
    "    elif item[1] == \"No\" and item[2] == \"No\":\n",
    "        perfect.append(item[0])\n",
    "        \n",
    "    elif item[1] == \"No\" and item[2] == \"Yes\":\n",
    "        data_loss.append(item[0])\n",
    "    else:\n",
    "        print(\"error item: \", item)\n",
    "\n",
    "print(len(recognizable), len(perfect), len(data_loss))        \n",
    "\n",
    "outputfolder = \"./image_data/recognizable_features\"\n",
    "if not os.path.exists(outputfolder):\n",
    "    os.makedirs(outputfolder)\n",
    "    \n",
    "nonfolder = \"./image_data/non_features\"\n",
    "if not os.path.exists(nonfolder):\n",
    "    os.makedirs(nonfolder)\n",
    "    \n",
    "perfectfolder = \"./image_data/perfect\"\n",
    "if not os.path.exists(perfectfolder):\n",
    "    os.makedirs(perfectfolder)\n",
    "\n",
    "for file in os.listdir(nifti_folder):\n",
    "    print(\"Processing File: \", file)\n",
    "    if file in recognizable:\n",
    "        print(\"sending to recognizable...\")\n",
    "        filepath = os.path.join(nifti_folder, file)\n",
    "        outputpath = os.path.join(outputfolder, file)\n",
    "        with open(filepath, 'rb') as f_in, open(outputpath, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    \n",
    "    elif file in perfect:\n",
    "        print(\"sending to perfect...\")\n",
    "        filepath = os.path.join(nifti_folder, file)\n",
    "        outputpath = os.path.join(perfectfolder, file)\n",
    "        with open(filepath, 'rb') as f_in, open(outputpath, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "            \n",
    "    elif file in data_loss:\n",
    "        print(\"sending to data_loss...\")\n",
    "        filepath = os.path.join(nifti_folder, file)\n",
    "        nonpath = os.path.join(nonfolder, file)\n",
    "        with open(filepath, 'rb') as f_in, open(nonpath, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    else:\n",
    "        print(\"error FILE: \", file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d33432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606011ec-17ff-4c78-be4b-03e5a44dd117",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stripped_folder = os.listdir(\"./image_data/recognizable_features\")\n",
    "stripped_folder = os.listdir(\"./image_data/non_features\")\n",
    "perfect_folder = os.listdir(\"./image_data/perfect\")\n",
    "\n",
    "non_strip = np.array([process_scan(os.path.join(\"./image_data/recognizable_features\",path)) for path in non_stripped_folder])\n",
    "print(\"Processed non_strip, moving to strip...\")\n",
    "stripped = np.array([process_scan(os.path.join(\"./image_data/non_features\",path)) for path in stripped_folder])\n",
    "print(\"Processed stripped moving to perfect...\")\n",
    "perfect = np.array([process_scan(os.path.join(\"./image_data/perfect\",path)) for path in perfect_folder])\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738390ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the arrays for later use\n",
    "np.save(\"non_strip.npy\", non_strip)\n",
    "np.save(\"stripped.npy\", stripped)\n",
    "np.save(\"perfect.npy\", perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4463db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run if you have already processed the numpy arrays\n",
    "non_strip = np.load(\"non_strip.npy\")\n",
    "stripped = np.load(\"stripped.npy\")\n",
    "perfect = np.load(\"perfect.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b559f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stripped shape: (1332, 128, 128, 64)\n",
      "Non-Strip shape: (713, 128, 128, 64)\n",
      "Perfect shape: (140, 128, 128, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Stripped shape:\",stripped.shape)\n",
    "print(\"Non-Strip shape:\",non_strip.shape)\n",
    "print(\"Perfect shape:\",perfect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90838c7e-641b-4206-8674-4211d1d41385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # correctly parse labels\n",
    "# csv = np.loadtxt(\"./data/labels.csv\", delimiter=\",\", dtype=str)\n",
    "\n",
    "# recognizable = []\n",
    "# unrecog = []\n",
    "# for item in csv:\n",
    "#     if item[1] == \"Yes\" and item[2] == \"No\":\n",
    "#         recognizable.append(item[0])\n",
    "#     else:\n",
    "#         unrecog.append(item[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d42eec0d-1f11-4214-b579-ca6aa5641122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train: (1529,) | x val: (656, 128, 128, 64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# shuffle the order of the arrays on the 1st dimension to produce different\n",
    "# test and train data for different runs\n",
    "np.random.shuffle(non_strip)\n",
    "np.random.shuffle(stripped)\n",
    "np.random.shuffle(perfect)\n",
    "\n",
    "# 1 == non_stripped and 0 == stripped and 2 == perfect\n",
    "non_strip_labels = np.array([1 for _ in range(len(non_strip))])\n",
    "strip_labels = np.array([0 for _ in range(len(stripped))])\n",
    "perfect_labels = np.array([2 for _ in range(len(perfect))])\n",
    "\n",
    "# split the training data into 70-30 ratio for training and validation\n",
    "# ratios were just calculated by hand (size*0.7)\n",
    "x_train = np.concatenate((stripped[:932], non_strip[:499], perfect[:98]),axis=0)\n",
    "y_train = np.concatenate((strip_labels[:932], non_strip_labels[:499], perfect_labels[:98]),axis=0)\n",
    "x_val = np.concatenate((stripped[932:], non_strip[499:], perfect[98:]),axis=0)\n",
    "y_val = np.concatenate((strip_labels[932:], non_strip_labels[499:], perfect_labels[98:]),axis=0)\n",
    "\n",
    "print(f\"y train: {y_train.shape} | x val: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3daf9fa-fecf-431f-95a6-5739fc0aff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1529, 128, 128, 64])\n",
      "torch.Size([1529, 128, 128, 64])\n",
      "torch.Size([1529])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "# turn x_train and y_train into a dataloader\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "print(x_train.shape)\n",
    "#x_train = np.transpose(x_train, (0,3,1,2)) \n",
    "print(x_train.shape)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long) # shape is (140)\n",
    "print(y_train.shape)\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True) #creates shape: (2, 64, 128, 128)\n",
    "\n",
    "\n",
    "# turn x_val and y_val into a dataloader\n",
    "x_val = torch.tensor(x_val, dtype=torch.float32)\n",
    "#x_val = np.transpose(x_val, (0,3,1,2))\n",
    "y_val = torch.tensor(y_val, dtype=torch.long) # shape is 60\n",
    "val_ds = TensorDataset(x_val, y_val)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94743d0-81e4-4d8a-9f6d-ccfb7d6d4ac4",
   "metadata": {},
   "source": [
    "# 3D PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05aaf34b-67f2-464b-9fd6-bab27db2182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class neuro_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(neuro_model, self).__init__()\n",
    "        \n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=(3, 3, 3), padding=1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=(3, 3, 3), padding=1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv3.weight)\n",
    "        \n",
    "        # Define the max pooling layers\n",
    "        self.pool = nn.MaxPool3d((2, 2, 2))\n",
    "        \n",
    "        # Define dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(2**17, 128)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "        # Define the activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional layers and activation function\n",
    "        x = x.unsqueeze(1) # unsqueeze to add channels 1\n",
    "        #print(\"input after unsqueeze:\", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        #print(\"shape after first conv layer\",x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        #print(\"shape after all conv layers\",x.shape)\n",
    "        # Reshape the tensor for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(\"shape after view\", x.shape)\n",
    "        # Apply the fully connected layers and activation function\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        #print(x.shape)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb18eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "def amp_fit(model):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # linear learning rate decay setup\n",
    "    n_t_steps = len(train_dl) * n_epochs\n",
    "    n_w_steps = .1 * n_t_steps\n",
    "    scheduler = get_linear_schedule_with_warmup(optim, n_w_steps, n_t_steps)\n",
    "\n",
    "    #batch accumulation parameter\n",
    "    accum_iter = 4\n",
    "\n",
    "    # other variables\n",
    "    total_loss = 0\n",
    "    total_time = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        for step, (inputs, labels) in enumerate(train_dl):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # amp scaler\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = outputs[0]\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # gradient accumulation that encompasses the functions of the amp scaler\n",
    "            if((step+1)%accum_iter == 0) or (step+1 == len(train_dl)):\n",
    "                scaler.step(optim)\n",
    "                scaler.update()\n",
    "                optim.zero_grad()\n",
    "                scheduler.step()\n",
    "            \n",
    "            # calculates the amount of time it takes to get through 10% of train_dl\n",
    "            if step % (len(train_dl)*.1) == 0:\n",
    "                epoch_time = time.perf_counter()\n",
    "                print(f\"Epoch: {epoch+1} | step: {step}/{len(train_dl)} | loss: {total_loss/(step+1):.4f} | time: {(epoch_time-start_time)/60:.1f} (minutes)\")\n",
    "            \n",
    "        total_time += (epoch_time-start_time)\n",
    "\n",
    "    print(f\"Total time: {total_time/360} (hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9bf987d5-ac27-4c26-903d-28ed20d0c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "\n",
    "def fit(model):\n",
    "    \n",
    "    loss_arr = []\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for step, (inputs, labels) in enumerate(train_dl):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(inputs)\n",
    "            #print(output)\n",
    "            #print(labels)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            \n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "        loss_arr.append(loss.item())    \n",
    "        print(f\"epoch: {epoch+1} | loss: {loss.item():4f}\")\n",
    "    \n",
    "    return loss_arr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2af6edbc-5cb3-4661-9c9e-a9702e0cc500",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neuro_model(\n",
       "  (conv1): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv2): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=131072, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "model = neuro_model()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3750bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss: 0.005439\n",
      "epoch: 2 | loss: 0.017541\n",
      "epoch: 3 | loss: 0.000137\n",
      "epoch: 4 | loss: 0.000149\n",
      "epoch: 5 | loss: 0.000461\n",
      "epoch: 6 | loss: 4.056888\n",
      "epoch: 7 | loss: 0.004548\n",
      "epoch: 8 | loss: 0.003874\n",
      "epoch: 9 | loss: 0.924718\n",
      "epoch: 10 | loss: 0.002280\n",
      "epoch: 11 | loss: 0.000148\n",
      "epoch: 12 | loss: 0.000795\n",
      "epoch: 13 | loss: 0.001706\n",
      "epoch: 14 | loss: 0.002361\n",
      "epoch: 15 | loss: 0.000178\n",
      "epoch: 16 | loss: 0.021618\n",
      "epoch: 17 | loss: 0.001359\n",
      "epoch: 18 | loss: 0.000410\n",
      "epoch: 19 | loss: 0.000003\n",
      "epoch: 20 | loss: 0.002944\n",
      "epoch: 21 | loss: 0.003172\n",
      "epoch: 22 | loss: 0.000000\n",
      "epoch: 23 | loss: 0.000001\n",
      "epoch: 24 | loss: 0.000000\n",
      "epoch: 25 | loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "larr = fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad7b413b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ./model does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./model/model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\serialization.py:422\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    419\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    423\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\serialization.py:309\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\serialization.py:287\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_zipfile_writer_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory ./model does not exist."
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './model/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4fefb71-1c66-4ce9-b75f-70f635505ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98%\n"
     ]
    }
   ],
   "source": [
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "            inp, val_outp = data\n",
    "            inp, val_outp = inp.cuda(), val_outp.cuda()\n",
    "            out = model(inp)\n",
    "            # shape (batch, 2)\n",
    "\n",
    "            _, pred = torch.max(out, 1)\n",
    "            \n",
    "#             print(\"correct:\", val_outp)\n",
    "#             print(\"pred:\", pred)\n",
    "            \n",
    "            total += val_outp.size(0)\n",
    "            correct += (pred == val_outp).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100*correct//total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81759dca-a3b9-4616-9cd0-0db357400a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99%\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in train_dl:\n",
    "            inp, val_outp = data\n",
    "            inp, val_outp = inp.cuda(), val_outp.cuda()\n",
    "            out = model(inp)\n",
    "            # shape (batch, 2)\n",
    "\n",
    "            _, pred = torch.max(out, 1)\n",
    "\n",
    "            total += val_outp.size(0)\n",
    "            correct += (pred == val_outp).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100*correct//total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cfdb34e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "yax = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "plt.plot(larr)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "\n",
    "plt.show()\n",
    "#print(larr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab1431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
